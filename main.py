"""
ä¸»è¦APIæ¨¡å—
é‡æ„åç‰ˆæœ¬ï¼šå»é™¤é‡å¤ä»£ç ï¼Œä½¿ç”¨å…¬å…±å·¥å…·
"""

from typing import List, Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed

# å¯¼å…¥å…¬å…±å·¥å…·å’Œé‡æ„åçš„LLMå®¢æˆ·ç«¯
from common_utils import FileUtils, TextProcessor, JSONProcessor, LogUtils, ConfigUtils
from LLMTool import LLMApiClient
from extract_variable import extract_variables_from_text


def process_text_with_llm(
    text: str,
    api_key: str = None,
    chunk_size: int = None,
    max_workers: int = None,
    config_file: str = None
) -> List[str]:
    """
    ä¸»APIå‡½æ•°ï¼šå¤„ç†æ–‡æœ¬å¹¶æå–å˜é‡
    
    Args:
        text: å¾…å¤„ç†çš„åŸå§‹æ–‡æœ¬
        api_key: APIå¯†é’¥ï¼Œå¦‚æœä¸æä¾›åˆ™ä»é…ç½®æ–‡ä»¶è¯»å–
        chunk_size: æ–‡æœ¬åˆ†å—å¤§å°ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨é…ç½®å€¼
        max_workers: å¹¶å‘å¤„ç†çš„çº¿ç¨‹æ•°ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨é…ç½®å€¼
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        æå–åˆ°çš„å˜é‡ååˆ—è¡¨
    """
    LogUtils.log_step("ä¸»APIå¤„ç†", "å¼€å§‹å¤„ç†æ–‡æœ¬å¹¶æå–å˜é‡")
    
    if not text or not text.strip():
        LogUtils.log_error("è¾“å…¥æ–‡æœ¬ä¸ºç©º")
        return []
    
    try:
        # ä½¿ç”¨é‡æ„åçš„å˜é‡æå–æ¨¡å—
        result = extract_variables_from_text(text, chunk_size, max_workers)
        
        if "error" in result:
            LogUtils.log_error(f"å¤„ç†å¤±è´¥: {result['error']}")
            return []
        
        variables = result.get("variables", [])
        LogUtils.log_success(f"APIå¤„ç†å®Œæˆï¼Œæå–åˆ° {len(variables)} ä¸ªå˜é‡")
        return variables
        
    except Exception as e:
        LogUtils.log_error(f"APIå¤„ç†å¼‚å¸¸: {e}")
        return []


def process_text_with_custom_prompt(
    text: str,
    system_prompt: str,
    api_key: str = None,
    chunk_size: int = None,
    max_workers: int = None
) -> List[str]:
    """
    ä½¿ç”¨è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºå¤„ç†æ–‡æœ¬
    
    Args:
        text: å¾…å¤„ç†çš„åŸå§‹æ–‡æœ¬
        system_prompt: è‡ªå®šä¹‰ç³»ç»Ÿæç¤º
        api_key: APIå¯†é’¥
        chunk_size: æ–‡æœ¬åˆ†å—å¤§å°
        max_workers: å¹¶å‘å¤„ç†çš„çº¿ç¨‹æ•°
        
    Returns:
        æå–åˆ°çš„å˜é‡ååˆ—è¡¨
    """
    LogUtils.log_step("è‡ªå®šä¹‰æç¤ºå¤„ç†", "ä½¿ç”¨è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºå¤„ç†æ–‡æœ¬")
    
    if not text or not system_prompt:
        LogUtils.log_error("æ–‡æœ¬æˆ–ç³»ç»Ÿæç¤ºä¸ºç©º")
        return []
    
    try:
        # è·å–é…ç½®
        config = ConfigUtils.get_config()
        chunk_size = chunk_size or config.get('chunk_size', 500)
        max_workers = max_workers or config.get('max_workers', 5)
        
        # åˆ›å»ºLLMå®¢æˆ·ç«¯
        llm_client = LLMApiClient(api_key)
        
        # ä½¿ç”¨å…¬å…±æ–‡æœ¬å¤„ç†å™¨åˆ†å‰²æ–‡æœ¬
        chunks = TextProcessor.split_text_by_length(text, chunk_size)
        LogUtils.log_info(f"æ–‡æœ¬å·²åˆ†å‰²ä¸º {len(chunks)} ä¸ªå—")
        
        # å¹¶å‘å¤„ç†
        results = {}
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {
                executor.submit(
                    _process_single_chunk,
                    chunk, system_prompt, llm_client
                ): i
                for i, chunk in enumerate(chunks)
            }
            
            for future in as_completed(futures):
                idx = futures[future]
                try:
                    variables = future.result()
                    results[idx] = variables
                    LogUtils.log_info(f"å— {idx} å¤„ç†å®Œæˆï¼Œæå–åˆ° {len(variables)} ä¸ªå˜é‡")
                except Exception as e:
                    LogUtils.log_error(f"å¤„ç†å— {idx} å¤±è´¥: {e}")
                    results[idx] = []
        
        # æ•´ç†ç»“æœ
        ordered_results = [results.get(i, []) for i in range(len(chunks))]
        all_variables = [var for sublist in ordered_results for var in sublist]
        unique_variables = list(set(all_variables))
        
        LogUtils.log_success(f"è‡ªå®šä¹‰æç¤ºå¤„ç†å®Œæˆï¼Œæå–åˆ° {len(unique_variables)} ä¸ªå”¯ä¸€å˜é‡")
        return unique_variables
        
    except Exception as e:
        LogUtils.log_error(f"è‡ªå®šä¹‰æç¤ºå¤„ç†å¼‚å¸¸: {e}")
        return []


def _process_single_chunk(chunk: str, system_prompt: str, llm_client: LLMApiClient) -> List[str]:
    """
    å¤„ç†å•ä¸ªæ–‡æœ¬å—
    
    Args:
        chunk: æ–‡æœ¬å—
        system_prompt: ç³»ç»Ÿæç¤º
        llm_client: LLMå®¢æˆ·ç«¯
        
    Returns:
        æå–åˆ°çš„å˜é‡åˆ—è¡¨
    """
    try:
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": chunk}
        ]
        
        response = llm_client.call(messages)
        if response:
            return JSONProcessor.extract_variables_from_json(response)
        else:
            return []
            
    except Exception as e:
        LogUtils.log_error(f"å¤„ç†å•ä¸ªå—å¤±è´¥: {e}")
        return []


def batch_process_texts(
    texts: List[str],
    api_key: str = None,
    chunk_size: int = None,
    max_workers: int = None
) -> List[List[str]]:
    """
    æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡æœ¬
    
    Args:
        texts: æ–‡æœ¬åˆ—è¡¨
        api_key: APIå¯†é’¥
        chunk_size: åˆ†å—å¤§å°
        max_workers: æœ€å¤§å¹¶å‘æ•°
        
    Returns:
        æ¯ä¸ªæ–‡æœ¬çš„å˜é‡åˆ—è¡¨
    """
    LogUtils.log_step("æ‰¹é‡å¤„ç†", f"å¼€å§‹å¤„ç† {len(texts)} ä¸ªæ–‡æœ¬")
    
    results = []
    for i, text in enumerate(texts):
        LogUtils.log_info(f"å¤„ç†ç¬¬ {i+1}/{len(texts)} ä¸ªæ–‡æœ¬")
        variables = process_text_with_llm(text, api_key, chunk_size, max_workers)
        results.append(variables)
    
    LogUtils.log_success("æ‰¹é‡å¤„ç†å®Œæˆ")
    return results


def analyze_text_statistics(text: str) -> Dict[str, Any]:
    """
    åˆ†ææ–‡æœ¬çš„åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
    
    Args:
        text: å¾…åˆ†æçš„æ–‡æœ¬
        
    Returns:
        ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    """
    if not text:
        return {"error": "æ–‡æœ¬ä¸ºç©º"}
    
    # åŸºæœ¬ç»Ÿè®¡
    stats = {
        "total_length": len(text),
        "total_lines": len(text.split('\n')),
        "total_words": len(text.split()),
        "total_paragraphs": len([p for p in text.split('\n\n') if p.strip()]),
    }
    
    # ä½¿ç”¨é…ç½®ä¼°ç®—åˆ†å—ä¿¡æ¯
    config = ConfigUtils.get_config()
    chunk_size = config.get('chunk_size', 500)
    chunks = TextProcessor.split_text_by_length(text, chunk_size)
    
    stats.update({
        "estimated_chunks": len(chunks),
        "chunk_size_used": chunk_size,
        "average_chunk_length": sum(len(chunk) for chunk in chunks) / len(chunks) if chunks else 0
    })
    
    return stats


def validate_input_file(file_path: str) -> Dict[str, Any]:
    """
    éªŒè¯è¾“å…¥æ–‡ä»¶
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        
    Returns:
        éªŒè¯ç»“æœ
    """
    result = {
        "valid": False,
        "file_exists": False,
        "readable": False,
        "content_length": 0,
        "error": None
    }
    
    try:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not FileUtils.read_file(file_path):
            result["error"] = f"æ–‡ä»¶ {file_path} ä¸å­˜åœ¨æˆ–æ— æ³•è¯»å–"
            return result
        
        result["file_exists"] = True
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        content = FileUtils.read_file(file_path)
        if content:
            result["readable"] = True
            result["content_length"] = len(content)
            
            if len(content.strip()) > 0:
                result["valid"] = True
            else:
                result["error"] = "æ–‡ä»¶å†…å®¹ä¸ºç©º"
        else:
            result["error"] = "æ— æ³•è¯»å–æ–‡ä»¶å†…å®¹"
            
    except Exception as e:
        result["error"] = f"éªŒè¯æ–‡ä»¶æ—¶å‡ºé”™: {e}"
    
    return result


def create_processing_report(
    input_file: str,
    variables: List[str],
    processing_time: float = None,
    statistics: Dict[str, Any] = None
) -> Dict[str, Any]:
    """
    åˆ›å»ºå¤„ç†æŠ¥å‘Š
    
    Args:
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
        variables: æå–åˆ°çš„å˜é‡
        processing_time: å¤„ç†æ—¶é—´ï¼ˆç§’ï¼‰
        statistics: å¤„ç†ç»Ÿè®¡ä¿¡æ¯
        
    Returns:
        å¤„ç†æŠ¥å‘Š
    """
    import datetime
    
    report = {
        "timestamp": datetime.datetime.now().isoformat(),
        "input_file": input_file,
        "total_variables": len(variables),
        "variables": variables,
        "processing_time_seconds": processing_time,
        "statistics": statistics or {}
    }
    
    # æ·»åŠ æ€§èƒ½è¯„ä¼°
    if processing_time and statistics:
        chars_per_second = statistics.get("total_length", 0) / processing_time if processing_time > 0 else 0
        report["performance"] = {
            "characters_per_second": round(chars_per_second, 2),
            "variables_per_minute": round(len(variables) * 60 / processing_time, 2) if processing_time > 0 else 0
        }
    
    return report


def main():
    """ä¸»å‡½æ•° - æä¾›å‘½ä»¤è¡Œæ¥å£"""
    import sys
    import time
    
    # ç®€å•çš„å‘½ä»¤è¡Œå‚æ•°å¤„ç†
    input_file = sys.argv[1] if len(sys.argv) > 1 else 'nl_prompt.txt'
    
    LogUtils.log_step("PromptSplit ä¸»API", f"å¤„ç†æ–‡ä»¶: {input_file}")
    
    # éªŒè¯è¾“å…¥æ–‡ä»¶
    validation = validate_input_file(input_file)
    if not validation["valid"]:
        LogUtils.log_error(f"æ–‡ä»¶éªŒè¯å¤±è´¥: {validation['error']}")
        return
    
    LogUtils.log_success(f"æ–‡ä»¶éªŒè¯é€šè¿‡ï¼Œé•¿åº¦: {validation['content_length']} å­—ç¬¦")
    
    try:
        # è¯»å–æ–‡æœ¬
        text = FileUtils.read_file(input_file)
        
        # åˆ†æç»Ÿè®¡ä¿¡æ¯
        stats = analyze_text_statistics(text)
        LogUtils.log_info(f"æ–‡æœ¬ç»Ÿè®¡: {stats['total_words']} è¯ï¼Œ{stats['estimated_chunks']} å—")
        
        # å¼€å§‹å¤„ç†
        start_time = time.time()
        variables = process_text_with_llm(text)
        end_time = time.time()
        
        processing_time = end_time - start_time
        
        # æ˜¾ç¤ºç»“æœ
        print(f"\nâœ… å¤„ç†å®Œæˆï¼å…±æå–åˆ° {len(variables)} ä¸ªå˜é‡ï¼š")
        for i, var in enumerate(variables, 1):
            print(f"  {i:2d}. {var}")
        
        print(f"\nâ±ï¸  å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’")
        print(f"ğŸ“Š å¤„ç†é€Ÿåº¦: {stats['total_length'] / processing_time:.0f} å­—ç¬¦/ç§’")
        
        # åˆ›å»ºå¹¶ä¿å­˜æŠ¥å‘Š
        report = create_processing_report(input_file, variables, processing_time, stats)
        if FileUtils.save_json("processing_report.json", report):
            LogUtils.log_success("å¤„ç†æŠ¥å‘Šå·²ä¿å­˜åˆ° processing_report.json")
        
    except Exception as e:
        LogUtils.log_error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")


if __name__ == '__main__':
    main()