"""
AIæç¤ºè¯æ™ºèƒ½æ‹†åˆ†å·¥å…· - Streamlit Webç•Œé¢
æä¾›ç°ä»£åŒ–çš„Webç•Œé¢ï¼Œæ”¯æŒå®æ—¶è¿›åº¦æ˜¾ç¤ºå’Œç»“æœå¯è§†åŒ–
"""
from urllib.parse import urlparse

import streamlit as st
import time
import json
import os
from typing import Dict, Any, Optional, Callable
import threading
from pathlib import Path

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="AIæç¤ºè¯æ™ºèƒ½æ‹†åˆ†å·¥å…·",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
/* ä¸»æ ‡é¢˜æ ·å¼ */
.main-title {
    text-align: center;
    font-size: 2.5rem;
    font-weight: bold;
    color: #1f77b4;
    margin-bottom: 2rem;
    padding: 1rem;
    background: linear-gradient(90deg, #e3f2fd, #ffffff, #e3f2fd);
    border-radius: 10px;
    border: 2px solid #1f77b4;
}

/* æ­¥éª¤å¡ç‰‡æ ·å¼ */
.step-card {
    background: #f8f9fa;
    padding: 1rem;
    border-radius: 10px;
    border-left: 4px solid #28a745;
    margin: 0.5rem 0;
}

.step-card.active {
    background: #e7f3ff;
    border-left-color: #007bff;
}

.step-card.completed {
    background: #d4edda;
    border-left-color: #28a745;
}

.step-card.error {
    background: #f8d7da;
    border-left-color: #dc3545;
}

/* ç»“æœå±•ç¤ºåŒºåŸŸ */
.result-container {
    background: #ffffff;
    padding: 1.5rem;
    border-radius: 15px;
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    margin: 1rem 0;
}

/* æˆåŠŸæç¤º */
.success-box {
    background: #d4edda;
    color: #155724;
    padding: 1rem;
    border-radius: 8px;
    border: 1px solid #c3e6cb;
    margin: 1rem 0;
}

/* é”™è¯¯æç¤º */
.error-box {
    background: #f8d7da;
    color: #721c24;
    padding: 1rem;
    border-radius: 8px;
    border: 1px solid #f5c6cb;
    margin: 1rem 0;
}

/* ç»Ÿè®¡ä¿¡æ¯å¡ç‰‡ */
.stat-card {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 1rem;
    border-radius: 10px;
    text-align: center;
    margin: 0.5rem;
}

.stat-number {
    font-size: 2rem;
    font-weight: bold;
}

.stat-label {
    font-size: 0.9rem;
    opacity: 0.9;
}
</style>
""", unsafe_allow_html=True)


class ProgressTracker:
    """è¿›åº¦è·Ÿè¸ªå™¨"""
    
    def __init__(self):
        self.reset()
    
    def reset(self):
        """é‡ç½®è¿›åº¦"""
        self.steps = [
            {"name": "è¾“å…¥éªŒè¯", "status": "pending", "message": "", "progress": 0, "result": None, "icon": "ğŸ”"},
            {"name": "æ–‡æœ¬åˆ†å—", "status": "pending", "message": "", "progress": 0, "result": None, "icon": "âœ‚ï¸"},
            {"name": "æå–å˜é‡", "status": "pending", "message": "", "progress": 0, "result": None, "icon": "ğŸ”¤"},
            {"name": "åå¤„ç†å˜é‡", "status": "pending", "message": "", "progress": 0, "result": None, "icon": "ğŸ”§"},
            {"name": "ç”ŸæˆMermaidå›¾", "status": "pending", "message": "", "progress": 0, "result": None, "icon": "ğŸ¨"},
            {"name": "æ‹†åˆ†å­ç³»ç»Ÿ", "status": "pending", "message": "", "progress": 0, "result": None, "icon": "ğŸ§©"},
            {"name": "ç”Ÿæˆå­æç¤ºè¯", "status": "pending", "message": "", "progress": 0, "result": None, "icon": "ğŸ“"},
            {"name": "ä»£ç ç”Ÿæˆ", "status": "pending", "message": "", "progress": 0, "result": None, "icon": "ğŸ’»"},
            {"name": "è½¬æ¢CNLP", "status": "pending", "message": "", "progress": 0, "result": None, "icon": "ğŸ”„"},
            {"name": "æ•´åˆç»“æœ", "status": "pending", "message": "", "progress": 0, "result": None, "icon": "ğŸ“‹"}
        ]
        self.current_step = 0
        self.overall_progress = 0
        self.logs = []
        self.result = None
        self.error = None
        self.processing_complete = False
        self.has_error = False
        self.start_time = None  # æ·»åŠ å¼€å§‹æ—¶é—´è®°å½•
    
    def start_step(self, step_index: int, message: str = ""):
        """å¼€å§‹æŸä¸ªæ­¥éª¤"""
        if 0 <= step_index < len(self.steps):
            # è®°å½•å¼€å§‹æ—¶é—´ï¼ˆç¬¬ä¸€ä¸ªæ­¥éª¤ï¼‰
            if self.start_time is None:
                import time
                self.start_time = time.time()
            
            self.current_step = step_index
            self.steps[step_index]["status"] = "active"
            self.steps[step_index]["message"] = message
            self.logs.append(f"ğŸ”„ {self.steps[step_index]['name']}: {message}")
    
    def complete_step(self, step_index: int, message: str = "å®Œæˆ", result_data: Any = None):
        """å®ŒæˆæŸä¸ªæ­¥éª¤"""
        if 0 <= step_index < len(self.steps):
            self.steps[step_index]["status"] = "completed"
            self.steps[step_index]["message"] = message
            self.steps[step_index]["progress"] = 100
            self.steps[step_index]["result"] = result_data
            self.overall_progress = min(100, (step_index + 1) * (100 / len(self.steps)))
            self.logs.append(f"âœ… {self.steps[step_index]['name']}: {message}")
    
    def error_step(self, step_index: int, error_message: str):
        """æ­¥éª¤å‡ºé”™"""
        if 0 <= step_index < len(self.steps):
            self.steps[step_index]["status"] = "error"
            self.steps[step_index]["message"] = error_message
            self.error = error_message
            self.logs.append(f"âŒ {self.steps[step_index]['name']}: {error_message}")
    
    def update_step_progress(self, step_index: int, progress: int, message: str = "", result_data: Any = None):
        """æ›´æ–°æ­¥éª¤è¿›åº¦"""
        if 0 <= step_index < len(self.steps):
            self.steps[step_index]["progress"] = progress
            if message:
                self.steps[step_index]["message"] = message
            if result_data is not None:
                self.steps[step_index]["result"] = result_data


def initialize_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    if "progress_tracker" not in st.session_state:
        st.session_state.progress_tracker = ProgressTracker()
    if "processing" not in st.session_state:
        st.session_state.processing = False
    if "result_data" not in st.session_state:
        st.session_state.result_data = None


def render_header():
    """æ¸²æŸ“é¡µé¢å¤´éƒ¨"""
    st.markdown("""
    <div class="main-title">
        ğŸ¤– AIæç¤ºè¯æ™ºèƒ½æ‹†åˆ†å·¥å…·
        <div style="font-size: 1rem; margin-top: 0.5rem; font-weight: normal;">
            æ™ºèƒ½æå–å˜é‡ â€¢ ç³»ç»ŸåŒ–æ‹†åˆ† â€¢ CNLPç»“æ„åŒ–è½¬æ¢
        </div>
    </div>
    """, unsafe_allow_html=True)


def render_input_section():
    """æ¸²æŸ“è¾“å…¥åŒºåŸŸ"""
    st.header("ğŸ“ è¾“å…¥é…ç½®")
    
    # APIé…ç½®åŒºåŸŸ
    render_api_config_section()
    
    st.markdown("---")
    
    # è¾“å…¥æ–¹å¼é€‰æ‹©
    input_method = st.radio(
        "é€‰æ‹©è¾“å…¥æ–¹å¼ï¼š",
        ["æ–‡æœ¬è¾“å…¥", "æ–‡ä»¶ä¸Šä¼ "],
        horizontal=True
    )
    
    input_text = ""
    
    if input_method == "æ–‡æœ¬è¾“å…¥":
        input_text = st.text_area(
            "è¯·è¾“å…¥éœ€è¦æ‹†åˆ†çš„æç¤ºè¯ï¼š",
            height=200,
            placeholder="è¯·è¾“å…¥æ‚¨çš„AIæç¤ºè¯å†…å®¹...\n\nç¤ºä¾‹ï¼šä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å˜é‡æŠ½å–å™¨ï¼Œè´Ÿè´£ä»ç”¨æˆ·æä¾›çš„æ–‡æœ¬ä¸­è¯†åˆ«å‡ºæ‰€æœ‰å¯èƒ½çš„å˜é‡..."
        )
    else:
        uploaded_file = st.file_uploader(
            "é€‰æ‹©æ–‡æœ¬æ–‡ä»¶",
            type=['txt', 'md'],
            help="æ”¯æŒ.txtå’Œ.mdæ–‡ä»¶æ ¼å¼"
        )
        
        if uploaded_file is not None:
            try:
                input_text = str(uploaded_file.read(), "utf-8")
                st.success(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼å†…å®¹é•¿åº¦ï¼š{len(input_text)} å­—ç¬¦")
                with st.expander("ğŸ“„ æ–‡ä»¶å†…å®¹é¢„è§ˆ"):
                    st.text(input_text[:500] + "..." if len(input_text) > 500 else input_text)
            except Exception as e:
                st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{e}")
    
    # å¤„ç†é…ç½®
    st.subheader("âš™ï¸ å¤„ç†é…ç½®")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        chunk_size = st.number_input("åˆ†å—å¤§å°", min_value=100, max_value=2000, value=500, step=50)
    with col2:
        max_workers = st.number_input("å¹¶å‘æ•°", min_value=1, max_value=10, value=5, step=1)
    with col3:
        show_debug = st.checkbox("æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—", value=False)
    
    return input_text, chunk_size, max_workers, show_debug


def render_api_config_section():
    """æ¸²æŸ“APIé…ç½®åŒºåŸŸ"""
    st.subheader("ğŸ”‘ APIé…ç½®")
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰API keyé…ç½®
    if 'api_key' not in st.session_state:
        st.session_state.api_key = ""
    if 'api_config_expanded' not in st.session_state:
        st.session_state.api_config_expanded = not st.session_state.api_key
    
    # APIçŠ¶æ€æ˜¾ç¤º
    col1, col2 = st.columns([3, 1])
    
    with col1:
        if st.session_state.api_key:
            masked_key = st.session_state.api_key[:8] + "*" * (len(st.session_state.api_key) - 12) + st.session_state.api_key[-4:]
            st.success(f"âœ… API Keyå·²é…ç½®: {masked_key}")
        else:
            st.warning("âš ï¸ è¯·é…ç½®æ‚¨çš„API Keyä»¥å¼€å§‹ä½¿ç”¨")
    
    with col2:
        if st.button("ğŸ”§ é…ç½®API", type="secondary"):
            st.session_state.api_config_expanded = not st.session_state.api_config_expanded
            st.rerun()
    
    # APIé…ç½®è¡¨å•
    if st.session_state.api_config_expanded:
        with st.expander("ğŸ”‘ API Keyé…ç½®", expanded=True):
            st.markdown("""
            **æ”¯æŒçš„AIæœåŠ¡å•†ï¼š**
            - Claude (Anthropic)
            - GPT (OpenAI)
            - å…¶ä»–å…¼å®¹OpenAI APIçš„æœåŠ¡
            
            **å¦‚ä½•è·å–API Keyï¼š**
            1. **Claude**: è®¿é—® [console.anthropic.com](https://console.anthropic.com) æ³¨å†Œå¹¶è·å–API Key
            2. **OpenAI**: è®¿é—® [platform.openai.com](https://platform.openai.com) æ³¨å†Œå¹¶è·å–API Key
            3. **å…¶ä»–æœåŠ¡**: æŸ¥çœ‹ç›¸åº”æœåŠ¡å•†çš„æ–‡æ¡£
            """)
            
            # API Keyè¾“å…¥
            api_key_input = st.text_input(
                "API Key",
                value=st.session_state.api_key,
                type="password",
                placeholder="è¯·è¾“å…¥æ‚¨çš„API Key (å¦‚: sk-ant-api03-...)",
                help="æ‚¨çš„API Keyå°†ä»…åœ¨æœ¬æ¬¡ä¼šè¯ä¸­ä½¿ç”¨ï¼Œä¸ä¼šè¢«å­˜å‚¨"
            )
            
            # APIæœåŠ¡é…ç½®
            col1, col2 = st.columns(2)
            
            with col1:
                api_base_url = st.text_input(
                    "API Base URL",
                    value=st.session_state.get('api_base_url', 'https://api.rcouyi.com'),
                    placeholder="https://api.rcouyi.com",
                    help="APIæœåŠ¡çš„åŸºç¡€URL"
                )
            
            with col2:
                api_model = st.selectbox(
                    "æ¨¡å‹é€‰æ‹©",
                    ["gpt-3.5-turbo", "gpt-4", "gpt-4-turbo", "gpt-5-mini", "gpt-5", "claude-3-sonnet-20240229", "claude-3-haiku-20240307"],
                    index=0,
                    help="é€‰æ‹©è¦ä½¿ç”¨çš„AIæ¨¡å‹"
                )
            
            # ä¿å­˜æŒ‰é’®
            col1, col2, col3 = st.columns([1, 1, 2])
            
            with col1:
                if st.button("ğŸ’¾ ä¿å­˜é…ç½®", type="primary"):
                    if api_key_input.strip():
                        st.session_state.api_key = api_key_input.strip()
                        st.session_state.api_base_url = api_base_url.strip()
                        st.session_state.api_model = api_model
                        st.session_state.api_config_expanded = False
                        
                        # æ›´æ–°é…ç½®æ–‡ä»¶
                        update_api_config(api_key_input.strip(), api_base_url.strip(), api_model)
                        
                        st.success("âœ… APIé…ç½®å·²ä¿å­˜")
                        time.sleep(1)
                        st.rerun()
                    else:
                        st.error("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„API Key")
            
            with col2:
                if st.button("ğŸ§ª æµ‹è¯•è¿æ¥"):
                    if api_key_input.strip():
                        with st.spinner("æµ‹è¯•APIè¿æ¥..."):
                            test_result = test_api_connection(api_key_input.strip(), api_base_url.strip(), api_model)
                            if test_result["success"]:
                                st.success(f"âœ… {test_result['message']}")
                            else:
                                st.error(f"âŒ {test_result['message']}")
                    else:
                        st.error("âŒ è¯·å…ˆè¾“å…¥API Key")
            
            with col3:
                st.markdown("""
                <div style="background-color: #f0f2f6; padding: 0.5rem; border-radius: 0.5rem; font-size: 0.8rem;">
                <strong>ğŸ’¡ å®‰å…¨æç¤º:</strong><br>
                â€¢ API Keyä»…åœ¨æµè§ˆå™¨ä¼šè¯ä¸­ä½¿ç”¨<br>
                â€¢ ä¸ä¼šä¸Šä¼ åˆ°æœåŠ¡å™¨æˆ–æ°¸ä¹…å­˜å‚¨<br>
                â€¢ å…³é—­æµè§ˆå™¨åéœ€è¦é‡æ–°è¾“å…¥
                </div>
                """, unsafe_allow_html=True)


def update_api_config(api_key: str, base_url: str, model: str):
    """æ›´æ–°APIé…ç½®åˆ°config.json"""
    try:
        from common_utils import ConfigUtils
        
        # è¯»å–ç°æœ‰é…ç½®
        config = ConfigUtils.get_config()
        
        # æ›´æ–°APIé…ç½®
        if 'api' not in config:
            config['api'] = {}
        
        # åªæ›´æ–°URLå’Œæ¨¡å‹ï¼Œä¸å­˜å‚¨API Keyï¼ˆå®‰å…¨è€ƒè™‘ï¼‰
        config['api']['url'] = base_url
        config['api']['model'] = model
        
        # ä¿å­˜é…ç½®
        ConfigUtils.save_config(config)
        
    except Exception as e:
        st.warning(f"âš ï¸ é…ç½®ä¿å­˜å¤±è´¥: {e}")


def setup_user_api_config(api_key: str, base_url: str, model: str):
    """è®¾ç½®ç”¨æˆ·çš„APIé…ç½®"""
    try:
        from LLMTool import LLMApiClient
        
        # è·å–å…¨å±€LLMå®¢æˆ·ç«¯å®ä¾‹å¹¶æ›´æ–°é…ç½®
        import first_spilit
        if hasattr(first_spilit, 'llm_client'):
            # éªŒè¯API keyä¸ä¸ºç©º
            if not api_key or not api_key.strip():
                st.error(" API Keyä¸èƒ½ä¸ºç©ºï¼Œè¯·è¾“å…¥æœ‰æ•ˆçš„API Key")
                return
            
            first_spilit.llm_client.api_key = api_key
            if base_url:
                # è§£æURLè®¾ç½®hostå’Œpath
                first_spilit.llm_client.api_key = api_key.strip()
                parsed = urlparse(base_url)
                first_spilit.llm_client.host = parsed.netloc
                
                # æ ¹æ®ä¸åŒçš„APIæœåŠ¡è®¾ç½®æ­£ç¡®çš„è·¯å¾„
                if "anthropic" in base_url.lower():
                    first_spilit.llm_client.path = "/v1/messages"
                elif "openai" in base_url.lower() or "rcouyi" in base_url.lower():
                    first_spilit.llm_client.path = "/v1/chat/completions"
                else:
                    # é»˜è®¤å°è¯•OpenAIå…¼å®¹æ ¼å¼
                    first_spilit.llm_client.path = "/v1/chat/completions"
                
                st.success(f"âœ… APIé…ç½®å·²æ›´æ–°: {first_spilit.llm_client.host}{first_spilit.llm_client.path}")
        
    except Exception as e:
        st.warning(f"âš ï¸ APIé…ç½®è®¾ç½®å¤±è´¥: {e}")


def test_api_connection(api_key: str, base_url: str, model: str) -> dict:
    """æµ‹è¯•APIè¿æ¥"""
    try:
        # åˆ›å»ºä¸´æ—¶çš„LLMå®¢æˆ·ç«¯è¿›è¡Œæµ‹è¯•
        from LLMTool import LLMApiClient
        
        # ä¸´æ—¶æ›´æ–°é…ç½®
        test_client = LLMApiClient()
        test_client.api_key = api_key
        
        if base_url:
            # è§£æURLè®¾ç½®hostå’Œpath
            from urllib.parse import urlparse
            parsed = urlparse(base_url)
            test_client.host = parsed.netloc
            
            # æ ¹æ®ä¸åŒçš„APIæœåŠ¡è®¾ç½®æ­£ç¡®çš„è·¯å¾„
            if "anthropic" in base_url.lower():
                test_client.path = "/v1/messages"
            elif "openai" in base_url.lower() or "rcouyi" in base_url.lower():
                test_client.path = "/v1/chat/completions"
            else:
                # é»˜è®¤å°è¯•OpenAIå…¼å®¹æ ¼å¼
                test_client.path = "/v1/chat/completions"
        
        # å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯·æ±‚
        test_messages = [
            {"role": "user", "content": "è¯·å›å¤'è¿æ¥æµ‹è¯•æˆåŠŸ'"}
        ]
        
        st.info(f"ğŸ” è°ƒè¯•ä¿¡æ¯: æ­£åœ¨æµ‹è¯• {test_client.host}{test_client.path}")
        
        response = test_client.call(test_messages, model)
        
        if response and "è¿æ¥æµ‹è¯•æˆåŠŸ" in response:
            return {"success": True, "message": "APIè¿æ¥æµ‹è¯•æˆåŠŸ"}
        elif response:
            return {"success": True, "message": f"APIè¿æ¥æˆåŠŸï¼Œæ¨¡å‹å“åº”æ­£å¸¸"}
        else:
            return {"success": False, "message": "APIè¿æ¥å¤±è´¥ï¼Œæœªæ”¶åˆ°å“åº”"}
            
    except Exception as e:
        error_msg = str(e)
        # æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        if "Connection" in error_msg:
            return {"success": False, "message": f"ç½‘ç»œè¿æ¥å¤±è´¥: æ— æ³•è¿æ¥åˆ° {base_url}"}
        elif "401" in error_msg or "Unauthorized" in error_msg:
            return {"success": False, "message": "è®¤è¯å¤±è´¥: API Keyæ— æ•ˆæˆ–æƒé™ä¸è¶³"}
        elif "404" in error_msg:
            return {"success": False, "message": "æœåŠ¡æœªæ‰¾åˆ°: è¯·æ£€æŸ¥API URLå’Œè·¯å¾„"}
        elif "429" in error_msg:
            return {"success": False, "message": "è¯·æ±‚è¿‡é¢‘: è¯·ç¨åé‡è¯•"}
        elif "500" in error_msg:
            return {"success": False, "message": "æœåŠ¡å™¨é”™è¯¯: APIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨"}
        else:
            return {"success": False, "message": f"è¿æ¥æµ‹è¯•å¤±è´¥: {error_msg}"}


def render_progress_section(tracker: ProgressTracker):
    """æ¸²æŸ“è¿›åº¦åŒºåŸŸ"""
    st.header("ğŸ“Š å¤„ç†è¿›åº¦")
    
    # æ•´ä½“è¿›åº¦æ¡
    progress_col1, progress_col2 = st.columns([3, 1])
    with progress_col1:
        st.progress(tracker.overall_progress / 100)
    with progress_col2:
        st.metric("æ•´ä½“è¿›åº¦", f"{tracker.overall_progress:.1f}%")
    
    # å½“å‰æ­¥éª¤ä¿¡æ¯
    if tracker.current_step < len(tracker.steps):
        current = tracker.steps[tracker.current_step]
        if current["status"] == "active":
            st.info(f"ğŸ”„ å½“å‰æ­¥éª¤: {current['name']} - {current['message']}")
        elif current["status"] == "error":
            st.error(f"âŒ æ­¥éª¤å¤±è´¥: {current['name']} - {current['message']}")
    
    # æ­¥éª¤è¯¦æƒ… - æ¯ä¸ªæ­¥éª¤å¯ç‹¬ç«‹å±•å¼€
    st.subheader("ğŸ“‹ è¯¦ç»†æ­¥éª¤")
    
    for i, step in enumerate(tracker.steps):
        status_icon = {
            "pending": "â³",
            "active": "ğŸ”„",
            "completed": "âœ…",
            "error": "âŒ"
        }.get(step["status"], "â³")
        
        progress_text = ""
        if step["progress"] > 0:
            progress_text = f" ({step['progress']}%)"
        
        # æ­¥éª¤æ ‡é¢˜
        step_title = f"{step['icon']} {step['name']}{progress_text}"
        if step["message"]:
            step_title += f" - {step['message']}"
        
        # æ ¹æ®çŠ¶æ€å†³å®šæ˜¯å¦å±•å¼€
        expanded = step["status"] in ["completed", "error"] and step.get("result") is not None
        
        with st.expander(f"{status_icon} {step_title}", expanded=expanded):
            if step["status"] == "completed" and step.get("result"):
                render_step_result(step["name"], step["result"])
            elif step["status"] == "error":
                st.error(f"âŒ é”™è¯¯: {step['message']}")
            elif step["status"] == "active":
                st.info(f"ğŸ”„ æ­£åœ¨å¤„ç†: {step['message']}")
            elif step["status"] == "pending":
                st.text("â³ ç­‰å¾…å¤„ç†...")
            else:
                st.text("ğŸ“ æš‚æ— è¯¦ç»†ä¿¡æ¯")


def render_step_result(step_name: str, result_data: Any):
    """æ¸²æŸ“æ­¥éª¤ç»“æœè¯¦æƒ…"""
    if not result_data:
        st.info("æš‚æ— ç»“æœæ•°æ®")
        return
    
    if step_name == "è¾“å…¥éªŒè¯":
        render_input_validation_result(result_data)
    elif step_name == "æ–‡æœ¬åˆ†å—":
        render_text_chunking_result(result_data)
    elif step_name == "æå–å˜é‡":
        render_variable_extraction_result(result_data)
    elif step_name == "åå¤„ç†å˜é‡":
        render_variable_processing_result(result_data)
    elif step_name == "ç”ŸæˆMermaidå›¾":
        render_mermaid_result(result_data)
    elif step_name == "æ‹†åˆ†å­ç³»ç»Ÿ":
        render_subsystem_result(result_data)
    elif step_name == "ç”Ÿæˆå­æç¤ºè¯":
        render_subprompt_result(result_data)
    elif step_name == "ä»£ç ç”Ÿæˆ":
        render_code_generation_result(result_data)
    elif step_name == "è½¬æ¢CNLP":
        render_cnlp_result(result_data)
    elif step_name == "æ•´åˆç»“æœ":
        render_integration_result(result_data)
    else:
        st.json(result_data)


def render_input_validation_result(data: Any):
    """æ¸²æŸ“è¾“å…¥éªŒè¯ç»“æœ"""
    if isinstance(data, dict):
        col1, col2 = st.columns(2)
        with col1:
            st.metric("æ–‡æœ¬é•¿åº¦", f"{data.get('length', 0)} å­—ç¬¦")
        with col2:
            st.metric("å­—ç¬¦ç¼–ç ", data.get('encoding', 'UTF-8'))
        
        if 'preview' in data:
            st.text_area("æ–‡æœ¬é¢„è§ˆ", data['preview'], height=100, disabled=True)
    else:
        st.text(f"éªŒè¯ç»“æœ: {data}")


def render_text_chunking_result(data: Any):
    """æ¸²æŸ“æ–‡æœ¬åˆ†å—ç»“æœ"""
    if isinstance(data, dict):
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("åˆ†å—æ•°é‡", data.get('chunk_count', 0))
        with col2:
            st.metric("å—å¤§å°", f"{data.get('chunk_size', 0)} å­—ç¬¦")
        with col3:
            st.metric("æ€»å­—ç¬¦æ•°", data.get('total_chars', 0))
        
        if 'chunks' in data:
            st.subheader("åˆ†å—è¯¦æƒ…")
            
            # åˆ†é¡µæ˜¾ç¤ºåˆ†å—ï¼Œé¿å…ç•Œé¢è¿‡é•¿
            chunks = data['chunks']
            total_chunks = len(chunks)
            chunks_per_page = 5
            
            # åˆå§‹åŒ–åˆ†é¡µå˜é‡
            start_idx = 0
            current_chunks = chunks
            
            # åˆ†é¡µæ§åˆ¶
            if total_chunks > chunks_per_page:
                col1, col2, col3 = st.columns([1, 2, 1])
                with col2:
                    current_page = st.selectbox(
                        "é€‰æ‹©åˆ†é¡µ",
                        options=list(range(1, (total_chunks - 1) // chunks_per_page + 2)),
                        index=0,
                        format_func=lambda x: f"ç¬¬ {x} é¡µ (æ˜¾ç¤º {min(chunks_per_page, total_chunks - (x-1)*chunks_per_page)} ä¸ªåˆ†å—)"
                    )
                
                # è®¡ç®—å½“å‰é¡µçš„åˆ†å—èŒƒå›´
                start_idx = (current_page - 1) * chunks_per_page
                end_idx = min(start_idx + chunks_per_page, total_chunks)
                current_chunks = chunks[start_idx:end_idx]
                
                st.info(f"ğŸ“„ ç¬¬ {current_page} é¡µï¼Œæ˜¾ç¤ºåˆ†å— {start_idx + 1}-{end_idx}ï¼Œå…± {total_chunks} ä¸ªåˆ†å—")
            else:
                st.info(f"ğŸ“Š å…±åˆ†å‰²å‡º {total_chunks} ä¸ªæ–‡æœ¬å—ï¼Œæ¯ä¸ªå—æœ€å¤§ {data.get('chunk_size', 0)} å­—ç¬¦")
            
            # æ˜¾ç¤ºå½“å‰é¡µçš„åˆ†å—
            for i, chunk in enumerate(current_chunks, start_idx + 1):
                with st.expander(f"åˆ†å— {i} ({len(chunk)} å­—ç¬¦)", expanded=(i <= 3)):
                    st.text(chunk)
    else:
        st.text(f"åˆ†å—ç»“æœ: {data}")


def render_variable_extraction_result(data: Any):
    """æ¸²æŸ“å˜é‡æå–ç»“æœ"""
    if isinstance(data, dict) and 'variables' in data:
        variables = data['variables']
        st.metric("æå–å˜é‡æ•°é‡", len(variables))
        
        if variables:
            st.subheader("æå–çš„å˜é‡")
            # ä»¥è¡¨æ ¼å½¢å¼æ˜¾ç¤ºå˜é‡
            var_data = []
            for i, var in enumerate(variables, 1):
                var_data.append({"åºå·": i, "å˜é‡å": var, "æ ¼å¼": f"{{{var}}}"})
            
            st.dataframe(var_data, use_container_width=True)
        else:
            st.warning("æœªæå–åˆ°å˜é‡")
    elif isinstance(data, list):
        st.metric("æå–å˜é‡æ•°é‡", len(data))
        for i, var in enumerate(data, 1):
            st.text(f"{i}. {{{var}}}")
    else:
        st.text(f"å˜é‡æå–ç»“æœ: {data}")


def render_variable_processing_result(data: Any):
    """æ¸²æŸ“å˜é‡åå¤„ç†ç»“æœ"""
    if isinstance(data, dict):
        if 'processed_text' in data:
            st.subheader("å¤„ç†åçš„æ–‡æœ¬")
            st.text_area("å¤„ç†åçš„æ–‡æœ¬å†…å®¹", data['processed_text'], height=200, disabled=True)
        
        if 'changes' in data:
            st.subheader("å¤„ç†å˜æ›´")
            for change in data['changes']:
                st.text(f"â€¢ {change}")
    else:
        st.text(f"åå¤„ç†ç»“æœ: {data}")


def render_mermaid_result(data: Any):
    """æ¸²æŸ“Mermaidå›¾ç»“æœ"""
    if isinstance(data, str):
        st.subheader("ç”Ÿæˆçš„Mermaidä»£ç ")
        st.code(data, language="mermaid")
        st.info("ğŸ’¡ æç¤º: æ‚¨å¯ä»¥å°†æ­¤ä»£ç å¤åˆ¶åˆ°Mermaidç¼–è¾‘å™¨ä¸­æŸ¥çœ‹å›¾å½¢")
    elif isinstance(data, dict) and 'mermaid_code' in data:
        st.subheader("ç”Ÿæˆçš„Mermaidä»£ç ")
        st.code(data['mermaid_code'], language="mermaid")
        if 'nodes_count' in data:
            st.metric("èŠ‚ç‚¹æ•°é‡", data['nodes_count'])
    else:
        st.text(f"Mermaidç”Ÿæˆç»“æœ: {data}")


def render_subsystem_result(data: Any):
    """æ¸²æŸ“å­ç³»ç»Ÿæ‹†åˆ†ç»“æœ"""
    if isinstance(data, dict) and 'subsystems' in data:
        subsystems = data['subsystems']
        st.metric("å­ç³»ç»Ÿæ•°é‡", len(subsystems))
        
        for i, subsystem in enumerate(subsystems, 1):
            with st.expander(f"å­ç³»ç»Ÿ {i}: {subsystem.get('name', 'æœªçŸ¥ç³»ç»Ÿ')}"):
                col1, col2 = st.columns(2)
                with col1:
                    st.text("**èŒè´£:**")
                    st.text(subsystem.get('responsibility', 'æ— æè¿°'))
                with col2:
                    st.text("**ç‹¬ç«‹æ€§:**")
                    st.text(subsystem.get('independence', 'æ— æè¿°'))
                
                st.text("**åä½œå…³ç³»:**")
                st.text(subsystem.get('collaboration', 'æ— æè¿°'))
                
                modules = subsystem.get('contained_modules', [])
                if modules:
                    st.text("**åŒ…å«æ¨¡å—:**")
                    st.text(", ".join(modules))
    else:
        st.text(f"å­ç³»ç»Ÿæ‹†åˆ†ç»“æœ: {data}")


def render_subprompt_result(data: Any):
    """æ¸²æŸ“å­æç¤ºè¯ç»“æœ"""
    if isinstance(data, dict) and 'subprompts' in data:
        subprompts = data['subprompts']
        st.metric("å­æç¤ºè¯æ•°é‡", len(subprompts))
        
        for i, prompt in enumerate(subprompts, 1):
            with st.expander(f"å­æç¤ºè¯ {i}: {prompt.get('name', f'æç¤ºè¯{i}')}"):
                if 'prompt' in prompt:
                    st.text_area("æç¤ºè¯å†…å®¹", prompt['prompt'], height=150, disabled=True)
                
                col1, col2 = st.columns(2)
                with col1:
                    if 'input' in prompt:
                        st.text("**è¾“å…¥:**")
                        st.text(prompt['input'])
                with col2:
                    if 'output' in prompt:
                        st.text("**è¾“å‡º:**")
                        st.text(prompt['output'])
    else:
        st.text(f"å­æç¤ºè¯ç”Ÿæˆç»“æœ: {data}")


def render_code_generation_result(data: Any):
    """æ¸²æŸ“ä»£ç ç”Ÿæˆç»“æœ"""
    if isinstance(data, dict) and 'results' in data:
        results = data['results']
        summary = data.get('summary', {})
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("æ€»å­ç³»ç»Ÿæ•°", summary.get('total_subprompts', 0))
        with col2:
            st.metric("å¯å®ç°æ•°", summary.get('implementable_count', 0))
        with col3:
            st.metric("ç”ŸæˆæˆåŠŸ", summary.get('successful_count', 0))
        with col4:
            st.metric("ç”Ÿæˆå¤±è´¥", summary.get('failed_count', 0))
        
        # æ˜¾ç¤ºæ¯ä¸ªå­ç³»ç»Ÿçš„ä»£ç ç”Ÿæˆç»“æœ
        for i, result in enumerate(results, 1):
            name = result.get('name', f'å­ç³»ç»Ÿ{i}')
            is_implementable = result.get('is_implementable', False)
            has_code = result.get('code') is not None
            
            # æ ¹æ®çŠ¶æ€é€‰æ‹©å›¾æ ‡å’Œæ ‡é¢˜é¢œè‰²
            if has_code:
                icon = "âœ…"
                status_color = "green"
            elif is_implementable:
                icon = "âš ï¸"
                status_color = "orange"
            else:
                icon = "âŒ"
                status_color = "red"
            
            with st.expander(f"{icon} å­ç³»ç»Ÿ {i}: {name}", expanded=False):
                if not is_implementable:
                    st.error(f"**ä¸é€‚åˆä»£ç å®ç°:** {result.get('reason', 'æœªçŸ¥åŸå› ')}")
                elif not has_code:
                    st.warning(f"**ä»£ç ç”Ÿæˆå¤±è´¥:** {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                else:
                    st.success("**ä»£ç ç”ŸæˆæˆåŠŸ**")
                    
                    # æ˜¾ç¤ºå®ç°æ³¨é‡Š
                    if result.get('annotation'):
                        st.info(f"**å®ç°æ€è·¯:** {result['annotation']}")
                    
                    # æ˜¾ç¤ºç”Ÿæˆçš„ä»£ç 
                    if result.get('code'):
                        st.subheader("ç”Ÿæˆçš„ä»£ç ")
                        st.code(result['code'], language="python")
                    
                    # æ˜¾ç¤ºæµ‹è¯•ç”¨ä¾‹
                    test_cases = result.get('test_cases', [])
                    if test_cases:
                        st.subheader(f"æµ‹è¯•ç”¨ä¾‹ ({len(test_cases)} ä¸ª)")
                        for j, test_case in enumerate(test_cases, 1):
                            with st.container():
                                st.write(f"**æµ‹è¯•ç”¨ä¾‹ {j}:**")
                                col_input, col_output = st.columns(2)
                                with col_input:
                                    st.write("**è¾“å…¥ä»£ç :**")
                                    st.code(test_case.get('input_code', ''), language="python")
                                with col_output:
                                    st.write("**é¢„æœŸè¾“å‡º:**")
                                    st.code(test_case.get('expected_output', ''), language="text")
                
                # æ˜¾ç¤ºåŸå§‹æç¤ºè¯ï¼ˆæŠ˜å çŠ¶æ€ï¼‰
                with st.expander("æŸ¥çœ‹åŸå§‹æç¤ºè¯", expanded=False):
                    st.text_area("åŸå§‹æç¤ºè¯", result.get('original_prompt', ''), height=100, disabled=True)
    else:
        st.text(f"ä»£ç ç”Ÿæˆç»“æœ: {data}")


def render_cnlp_result(data: Any):
    """æ¸²æŸ“CNLPè½¬æ¢ç»“æœ"""
    if isinstance(data, dict) and 'cnlp_results' in data:
        results = data['cnlp_results']
        st.metric("CNLPç»“æ„æ•°é‡", len(results))
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("è½¬æ¢æˆåŠŸ", data.get('success_count', 0))
        with col2:
            st.metric("è½¬æ¢å¤±è´¥", data.get('failed_count', 0))
        with col3:
            st.metric("æ€»æ•°", data.get('total_count', 0))
        
        for i, result in enumerate(results, 1):
            with st.expander(f"CNLP {i}: {result.get('name', f'ç»“æ„{i}')}"):
                if 'cnlp' in result:
                    st.code(result['cnlp'], language="yaml")
    else:
        st.text(f"CNLPè½¬æ¢ç»“æœ: {data}")


def render_integration_result(data: Any):
    """æ¸²æŸ“æ•´åˆç»“æœ"""
    if isinstance(data, dict):
        st.success("ğŸ‰ æ‰€æœ‰æ­¥éª¤å·²å®Œæˆï¼")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("å¤„ç†æ­¥éª¤", len(data.get('completed_steps', [])))
        with col2:
            st.metric("æ€»è€—æ—¶", f"{data.get('total_time', 0):.1f}ç§’")
        with col3:
            st.metric("æ•°æ®å®Œæ•´æ€§", "100%" if data.get('complete', True) else "éƒ¨åˆ†")
        
        if 'summary' in data:
            st.subheader("å¤„ç†æ‘˜è¦")
            st.json(data['summary'])
    else:
        st.text(f"æ•´åˆç»“æœ: {data}")


def render_logs_section(tracker: ProgressTracker, show_debug: bool):
    """æ¸²æŸ“æ—¥å¿—åŒºåŸŸ"""
    if show_debug and tracker.logs:
        with st.expander("ğŸ” è¯¦ç»†æ—¥å¿—", expanded=False):
            for log in tracker.logs[-20:]:  # åªæ˜¾ç¤ºæœ€è¿‘20æ¡
                st.text(log)


def render_results_section(result_data: Dict[str, Any]):
    """æ¸²æŸ“ç»“æœåŒºåŸŸ"""
    if not result_data:
        return
    
    st.header("ğŸ“‹ å¤„ç†ç»“æœ")
    
    # ç»Ÿè®¡ä¿¡æ¯
    st.subheader("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯")
    col1, col2, col3, col4 = st.columns(4)
    
    # æå–ç»Ÿè®¡æ•°æ®
    step1_data = result_data.get("step1_result", {})
    step2_data = result_data.get("step2_result", {})
    step3_data = result_data.get("step3_result", {})
    
    variables_count = len(step1_data.get("variables", []))
    subsystems_count = len(step2_data.get("subsystems", {}).get("subsystems", []))
    subprompts_count = len(step2_data.get("subprompts", {}).get("subprompts", []))
    cnlp_count = len(step3_data.get("cnlp_results", []))
    
    with col1:
        st.markdown(f"""
        <div class="stat-card">
            <div class="stat-number">{variables_count}</div>
            <div class="stat-label">æå–å˜é‡</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div class="stat-card">
            <div class="stat-number">{subsystems_count}</div>
            <div class="stat-label">å­ç³»ç»Ÿ</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div class="stat-card">
            <div class="stat-number">{subprompts_count}</div>
            <div class="stat-label">å­æç¤ºè¯</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        st.markdown(f"""
        <div class="stat-card">
            <div class="stat-number">{cnlp_count}</div>
            <div class="stat-label">CNLPç»“æœ</div>
        </div>
        """, unsafe_allow_html=True)
    
    # ç»“æœé€‰é¡¹å¡
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ”¤ æå–å˜é‡", "ğŸ§© å­ç³»ç»Ÿæ‹†åˆ†", "ğŸ“ CNLPç»“æœ", "ğŸ”— åä½œå…³ç³»"])
    
    with tab1:
        render_variables_tab(step1_data)
    
    with tab2:
        render_subsystems_tab(step2_data)
    
    with tab3:
        render_cnlp_tab(step3_data)
    
    with tab4:
        render_collaboration_tab(step2_data)


def render_variables_tab(step1_data: Dict[str, Any]):
    """æ¸²æŸ“å˜é‡æå–ç»“æœ"""
    variables = step1_data.get("variables", [])
    
    if variables:
        st.success(f"âœ… æˆåŠŸæå– {len(variables)} ä¸ªå˜é‡")
        
        # å˜é‡åˆ—è¡¨
        for i, var in enumerate(variables, 1):
            st.markdown(f"**{i}.** `{{{var}}}`")
        
        # å¤„ç†åçš„æ–‡æœ¬
        if "text_with_vars" in step1_data:
            st.subheader("ğŸ“„ å˜é‡æ ‡è®°åçš„æ–‡æœ¬")
            with st.expander("æŸ¥çœ‹å®Œæ•´æ–‡æœ¬"):
                st.text(step1_data["text_with_vars"])
    else:
        st.warning("âš ï¸ æœªæå–åˆ°å˜é‡")


def render_subsystems_tab(step2_data: Dict[str, Any]):
    """æ¸²æŸ“å­ç³»ç»Ÿæ‹†åˆ†ç»“æœ"""
    subsystems_data = step2_data.get("subsystems", {})
    subsystems = subsystems_data.get("subsystems", [])
    
    if subsystems:
        st.success(f"âœ… æˆåŠŸæ‹†åˆ† {len(subsystems)} ä¸ªå­ç³»ç»Ÿ")
        
        for i, subsystem in enumerate(subsystems, 1):
            with st.expander(f"ğŸ”§ å­ç³»ç»Ÿ {i}: {subsystem.get('name', 'æœªçŸ¥ç³»ç»Ÿ')}"):
                st.markdown(f"**èŒè´£**: {subsystem.get('responsibility', 'æ— æè¿°')}")
                st.markdown(f"**ç‹¬ç«‹æ€§**: {subsystem.get('independence', 'æ— æè¿°')}")
                st.markdown(f"**åä½œå…³ç³»**: {subsystem.get('collaboration', 'æ— æè¿°')}")
                
                modules = subsystem.get('contained_modules', [])
                if modules:
                    st.markdown(f"**åŒ…å«æ¨¡å—**: {', '.join(modules)}")
    
    # Mermaidå›¾
    mermaid_content = step2_data.get("mermaid_content", "")
    if mermaid_content:
        st.subheader("ğŸ¨ ç³»ç»Ÿæµç¨‹å›¾")
        with st.expander("æŸ¥çœ‹Mermaidä»£ç "):
            st.code(mermaid_content, language="mermaid")


def render_cnlp_tab(step3_data: Dict[str, Any]):
    """æ¸²æŸ“CNLPç»“æœ"""
    cnlp_results = step3_data.get("cnlp_results", [])
    
    if cnlp_results:
        st.success(f"âœ… æˆåŠŸç”Ÿæˆ {len(cnlp_results)} ä¸ªCNLPç»“æ„")
        
        for i, cnlp in enumerate(cnlp_results, 1):
            with st.expander(f"ğŸ“‹ CNLP {i}: {cnlp.get('title', f'ç»“æ„{i}')}"):
                st.json(cnlp)
    else:
        st.warning("âš ï¸ æœªç”ŸæˆCNLPç»“æœ")


def render_collaboration_tab(step2_data: Dict[str, Any]):
    """æ¸²æŸ“åä½œå…³ç³»"""
    subsystems_data = step2_data.get("subsystems", {})
    subsystems = subsystems_data.get("subsystems", [])
    
    if subsystems:
        st.success("ğŸ”— ç³»ç»Ÿåä½œå…³ç³»å›¾")
        
        # æ–‡æœ¬å½¢å¼çš„åä½œå…³ç³»
        collaboration_text = ""
        for i, subsystem in enumerate(subsystems, 1):
            name = subsystem.get('name', f'ç³»ç»Ÿ{i}')
            collaboration = subsystem.get('collaboration', 'æ— åä½œä¿¡æ¯')
            collaboration_text += f"**{name}**:\n{collaboration}\n\n"
        
        st.markdown(collaboration_text)
        
        st.info("ğŸ’¡ åç»­ç‰ˆæœ¬å°†æ”¯æŒäº¤äº’å¼Mermaidæµç¨‹å›¾æ¸²æŸ“")
    else:
        st.warning("âš ï¸ æ— åä½œå…³ç³»æ•°æ®")


def process_text_async(input_text: str, chunk_size: int, max_workers: int, tracker: ProgressTracker):
    """å¼‚æ­¥å¤„ç†æ–‡æœ¬ï¼Œä½¿ç”¨ä¼˜åŒ–çš„è¿›åº¦å›è°ƒç³»ç»Ÿ"""
    try:
        # å¯¼å…¥å¤„ç†æ¨¡å—
        from run_split import PromptSplitPipeline
        from common_utils import LogUtils, ConfigUtils
        
        # å®šä¹‰æ­¥éª¤åˆ°ç´¢å¼•çš„æ˜ å°„
        step_mapping = {
            "è¾“å…¥éªŒè¯": 0,
            "æ–‡æœ¬åˆ†å—": 1,
            "æå–å˜é‡": 2,
            "åå¤„ç†å˜é‡": 3,
            "ç”ŸæˆMermaidå›¾": 4,
            "æ‹†åˆ†å­ç³»ç»Ÿ": 5,
            "ç”Ÿæˆå­æç¤ºè¯": 6,
            "ä»£ç ç”Ÿæˆ": 7,
            "è½¬æ¢CNLP": 8,
            "æ•´åˆç»“æœ": 9
        }
        
        # åˆ›å»ºè¿›åº¦å›è°ƒå‡½æ•°
        def progress_callback(step_name: str, progress: int, message: str = "", result_data: Any = None):
            """è¿›åº¦å›è°ƒå‡½æ•°ï¼Œå°†pipelineè¿›åº¦æ˜ å°„åˆ°UIè¿›åº¦"""
            if step_name in step_mapping:
                step_idx = step_mapping[step_name]
                if progress == 0:
                    tracker.start_step(step_idx, message)
                elif progress == 100:
                    tracker.complete_step(step_idx, message, result_data)
                else:
                    tracker.update_step_progress(step_idx, progress, message, result_data)
        
        # åˆ›å»ºå¸¦è¿›åº¦å›è°ƒçš„å¤„ç†ç®¡é“
        pipeline = PromptSplitPipeline(progress_callback=progress_callback)
        
        # ä½¿ç”¨ç”¨æˆ·é…ç½®çš„API Key
        if st.session_state.get('api_key'):
            setup_user_api_config(st.session_state.api_key, 
                                 st.session_state.get('api_base_url', ''), 
                                 st.session_state.get('api_model', ''))
        
        # è¾“å…¥éªŒè¯æ­¥éª¤ï¼ˆå•ç‹¬å¤„ç†ï¼Œå› ä¸ºè¿™æ˜¯UIå±‚é¢çš„éªŒè¯ï¼‰
        tracker.start_step(step_mapping["è¾“å…¥éªŒè¯"], "éªŒè¯è¾“å…¥æ–‡æœ¬...")
        validation_result = {
            "length": len(input_text),
            "encoding": "UTF-8",
            "preview": input_text[:200] + "..." if len(input_text) > 200 else input_text
        }
        tracker.complete_step(step_mapping["è¾“å…¥éªŒè¯"], f"æ–‡æœ¬é•¿åº¦: {len(input_text)} å­—ç¬¦", validation_result)
        
        # æ­¥éª¤1: å˜é‡æå–ï¼ˆç°åœ¨ä¼šé€šè¿‡è¿›åº¦å›è°ƒè‡ªåŠ¨æ›´æ–°ç»“æœï¼‰
        step1_result = pipeline.step1_extract_variables(input_text)
        if "error" in step1_result:
            tracker.error_step(step_mapping.get("æå–å˜é‡", 2), step1_result["error"])
            return
        
        # æ­¥éª¤2: å­ç³»ç»Ÿæ‹†åˆ†ï¼ˆç°åœ¨ä¼šé€šè¿‡è¿›åº¦å›è°ƒè‡ªåŠ¨æ›´æ–°ç»“æœï¼‰
        step2_result = pipeline.step2_split_to_subprompts(step1_result["text_with_vars"])
        if "error" in step2_result:
            tracker.error_step(step_mapping.get("æ‹†åˆ†å­ç³»ç»Ÿ", 5), step2_result["error"])
            return
        
        # æ­¥éª¤2.5: ä»£ç ç”Ÿæˆï¼ˆæ–°å¢æ­¥éª¤ï¼Œå¯é…ç½®ç¦ç”¨ï¼‰
        config = ConfigUtils.get_config()
        code_generation_enabled = config.get('step2_5_code_generation', {}).get('enabled', True)
        
        if code_generation_enabled:
            step2_5_result = pipeline.step2_5_generate_code(step2_result.get("subprompts", {}))
            if "error" in step2_5_result:
                # ä»£ç ç”Ÿæˆå¤±è´¥ä¸ä¸­æ–­æ•´ä¸ªæµç¨‹ï¼Œåªè®°å½•è­¦å‘Š
                LogUtils.log_warning(f"ä»£ç ç”Ÿæˆå¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œåç»­æ­¥éª¤: {step2_5_result['error']}")
                step2_5_result = {"error": step2_5_result["error"], "results": []}
        else:
            LogUtils.log_info("ä»£ç ç”Ÿæˆæ­¥éª¤å·²ç¦ç”¨ï¼Œè·³è¿‡...")
            step2_5_result = {
                "summary": {"total_count": 0, "implementable_count": 0, "successful_count": 0, "failed_count": 0},
                "results": [],
                "disabled": True
            }
        
        # æ­¥éª¤3: CNLPè½¬æ¢ï¼ˆè·³è¿‡å·²ç”Ÿæˆä»£ç çš„å­ç³»ç»Ÿï¼‰
        step3_result = pipeline.step3_convert_to_cnlp(step2_result.get("subprompts", {}), step2_5_result)
        if "error" in step3_result:
            tracker.error_step(step_mapping.get("è½¬æ¢CNLP", 8), step3_result["error"])
            return
        
        # æœ€ç»ˆæ•´åˆ
        tracker.start_step(step_mapping["æ•´åˆç»“æœ"], "æ•´åˆæœ€ç»ˆç»“æœ...")
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        end_time = time.time()
        # ä½¿ç”¨çœŸå®çš„å¤„ç†æ—¶é—´
        if tracker.start_time:
            processing_time = end_time - tracker.start_time
        else:
            processing_time = 0.0  # åå¤‡æ–¹æ¡ˆ
        
        integration_summary = {
            "completed_steps": [step["name"] for step in tracker.steps if step["status"] == "completed"],
            "total_time": round(processing_time, 2),
            "complete": True,
            "summary": {
                "variables_extracted": len(step1_result.get("variables", [])),
                "subsystems_created": len(step2_result.get("subsystems", {}).get("subsystems", [])),
                "subprompts_generated": len(step2_result.get("subprompts", {}).get("subprompts", [])),
                "code_implementable": step2_5_result.get("summary", {}).get("implementable_count", 0),
                "code_successful": step2_5_result.get("summary", {}).get("successful_count", 0),
                "cnlp_converted": len(step3_result.get("cnlp_results", [])),
                "cnlp_skipped": step3_result.get("skipped_count", 0)
            }
        }
        
        final_result = {
            "step1_result": step1_result,
            "step2_result": step2_result,
            "step2_5_result": step2_5_result,
            "step3_result": step3_result,
            "processing_time": time.time()
        }
        
        tracker.complete_step(step_mapping["æ•´åˆç»“æœ"], "å¤„ç†å®Œæˆ", integration_summary)
        
        # è®¾ç½®ç»“æœå’Œå®ŒæˆçŠ¶æ€
        tracker.result = final_result
        tracker.processing_complete = True
        
        # æ³¨æ„ï¼šä¸åœ¨åå°çº¿ç¨‹ä¸­ç›´æ¥æ“ä½œst.session_stateï¼Œé¿å…ScriptRunContextè­¦å‘Š
        # ä¼šè¯çŠ¶æ€æ›´æ–°å°†åœ¨ä¸»çº¿ç¨‹ä¸­å¤„ç†
        
    except Exception as e:
        tracker.error_step(tracker.current_step, f"å¤„ç†å¼‚å¸¸: {str(e)}")
        tracker.processing_complete = True
        tracker.has_error = True


def main():
    """ä¸»å‡½æ•°"""
    initialize_session_state()
    
    # æ¸²æŸ“é¡µé¢
    render_header()
    
    # è¾“å…¥åŒºåŸŸ
    input_text, chunk_size, max_workers, show_debug = render_input_section()
    
    # å¼€å§‹å¤„ç†æŒ‰é’®
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        # æ£€æŸ¥APIé…ç½®çŠ¶æ€
        api_configured = bool(st.session_state.get('api_key'))
        
        if st.button("ğŸš€ å¼€å§‹å¤„ç†", type="primary", use_container_width=True, disabled=not api_configured):
            if not api_configured:
                st.error("âŒ è¯·å…ˆé…ç½®API Key")
            elif input_text.strip():
                st.session_state.processing = True
                st.session_state.progress_tracker.reset()
                st.session_state.result_data = None
                
                # å¯åŠ¨å¼‚æ­¥å¤„ç†
                threading.Thread(
                    target=process_text_async,
                    args=(input_text, chunk_size, max_workers, st.session_state.progress_tracker)
                ).start()
                
                st.rerun()
            else:
                st.error("âŒ è¯·è¾“å…¥éœ€è¦å¤„ç†çš„æ–‡æœ¬å†…å®¹")
        
        # æç¤ºä¿¡æ¯
        if not api_configured:
            st.info("ğŸ’¡ è¯·å…ˆåœ¨ä¸Šæ–¹é…ç½®æ‚¨çš„API Keyæ‰èƒ½å¼€å§‹å¤„ç†")
    
    # è¿›åº¦åŒºåŸŸ
    if st.session_state.processing or st.session_state.progress_tracker.overall_progress > 0:
        render_progress_section(st.session_state.progress_tracker)
        render_logs_section(st.session_state.progress_tracker, show_debug)
        
        # æ£€æŸ¥åå°å¤„ç†æ˜¯å¦å®Œæˆï¼ˆé¿å…åœ¨åå°çº¿ç¨‹ä¸­ç›´æ¥æ“ä½œsession_stateï¼‰
        if st.session_state.processing:
            tracker = st.session_state.progress_tracker
            if tracker.processing_complete:
                # å¤„ç†å®Œæˆï¼Œæ›´æ–°session_state
                st.session_state.processing = False
                if tracker.result and not tracker.has_error:
                    st.session_state.result_data = tracker.result
                    st.success("ğŸ‰ å¤„ç†å®Œæˆï¼")
                elif tracker.has_error:
                    st.error("âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œè¯·æŸ¥çœ‹è¯¦ç»†æ—¥å¿—")
            else:
                # ç»§ç»­å¤„ç†ä¸­ï¼Œè‡ªåŠ¨åˆ·æ–°
                time.sleep(1)
                st.rerun()
    
    # ç»“æœåŒºåŸŸ
    if st.session_state.result_data:
        render_results_section(st.session_state.result_data)
        
        # ä¸‹è½½ç»“æœæŒ‰é’®
        st.subheader("ğŸ’¾ å¯¼å‡ºç»“æœ")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            result_json = json.dumps(st.session_state.result_data, ensure_ascii=False, indent=2)
            st.download_button(
                "ğŸ“„ ä¸‹è½½JSONç»“æœ",
                result_json,
                "prompt_split_result.json",
                "application/json"
            )
        
        with col2:
            # ç”Ÿæˆå¤„ç†æŠ¥å‘Š
            variables = st.session_state.result_data["step1_result"].get("variables", [])
            code_summary = st.session_state.result_data.get("step2_5_result", {}).get("summary", {})
            report = f"""# AIæç¤ºè¯æ‹†åˆ†å¤„ç†æŠ¥å‘Š

## å¤„ç†ç»Ÿè®¡
- æå–å˜é‡æ•°é‡: {len(variables)}
- å­ç³»ç»Ÿæ•°é‡: {len(st.session_state.result_data["step2_result"].get("subsystems", {}).get("subsystems", []))}
- å¯å®ç°ä»£ç æ•°é‡: {code_summary.get("implementable_count", 0)}
- æˆåŠŸç”Ÿæˆä»£ç æ•°é‡: {code_summary.get("successful_count", 0)}
- ç”ŸæˆCNLPæ•°é‡: {len(st.session_state.result_data["step3_result"].get("cnlp_results", []))}

## æå–çš„å˜é‡
{chr(10).join([f"- {{{var}}}" for var in variables])}

## å¤„ç†æ—¶é—´
{time.strftime('%Y-%m-%d %H:%M:%S')}
"""
            st.download_button(
                "ğŸ“Š ä¸‹è½½å¤„ç†æŠ¥å‘Š",
                report,
                "prompt_split_report.md",
                "text/markdown"
            )


if __name__ == "__main__":
    main() 